{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Description\n",
    "\n",
    "This notebook processes audio datasets by extracting embeddings using the **Birdnetlib library** and saving the results to CSV files. It is designed to handle multiple bird species datasets and ensures efficient processing with memory management and progress tracking.\n",
    "\n",
    "### **Main Tasks:**\n",
    "\n",
    "1. **Load and Organize Audio Files:**\n",
    "   - Dynamically retrieves `.wav` audio files from the Extended_audios directory for the following datasets:\n",
    "     - `chiffchaff-fg`\n",
    "     - `littleowl-fg`\n",
    "     - `pipit-fg`\n",
    "     - `rtbc-begging`\n",
    "     - `littlepenguin-display_call-exhale`\n",
    "     - `greatTit_song-files`\n",
    "   - Prints the number of audio files found for each dataset and verifies the first few file paths.\n",
    "\n",
    "2. **Set Up Output Directory and CSV Files:**\n",
    "   - Creates an output directory (Embeddings_from_3sPadding) if it does not exist.\n",
    "   - Defines separate CSV files for each dataset to store the extracted embeddings.\n",
    "\n",
    "3. **Extract Embeddings Using BirdNET:**\n",
    "   - Initializes the BirdNET model (`Analyzer`).\n",
    "   - Iterates through the audio files, skipping already processed files (tracked in the CSV).\n",
    "   - For each audio file:\n",
    "     - Loads the file into BirdNET.\n",
    "     - Extracts embeddings and metadata (e.g., start time, end time).\n",
    "     - Saves the embeddings to the corresponding CSV file in batches of 200 files to optimize memory usage.\n",
    "\n",
    "4. **Handle Errors and Memory Management:**\n",
    "   - Skips files that cannot be processed and logs errors.\n",
    "   - Clears memory after processing each batch to ensure efficient execution.\n",
    "\n",
    "5. **Post-Processing Analysis:**\n",
    "   - Compares the original list of audio files with the processed files in the CSV.\n",
    "   - Reports the total number of processed, unprocessed, and skipped files.\n",
    "   - Displays a list of unprocessed audio files for further investigation.\n",
    "\n",
    "### **Output:**\n",
    "- CSV files containing embeddings for each dataset, saved in the directory:\n",
    "  ```\n",
    "  Output_files/Embeddings_from_3sPadding/\n",
    "  ```\n",
    "  Example:  `greatTit_embeddings.csv`, etc.\n",
    "\n",
    "### **Key Features:**\n",
    "- Efficient batch processing with progress updates every 200 files.\n",
    "- Skips already processed files to avoid duplication.\n",
    "- Handles large datasets with memory management and error handling.\n",
    "- Provides detailed statistics on processed and unprocessed files.\n",
    "\n",
    "This notebook ensures that audio embeddings are extracted and saved efficiently, making the datasets ready for further analysis or machine learning workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found:\n",
      "Audios chiffchaff: 6762\n",
      "Audios littleowl: 952\n",
      "Audios pipit: 1364\n",
      "Audios rtbc: 1785\n",
      "Audios littlepenguin: 2429\n",
      "Audios greatTit: 74048\n",
      "['/teamspace/studios/this_studio/Output_files/Extended_audios/chiffchaff-fg/cutted_day1_PC1101_0000.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/chiffchaff-fg/cutted_day1_PC1101_0001.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/chiffchaff-fg/cutted_day1_PC1101_0002.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/chiffchaff-fg/cutted_day1_PC1101_0003.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/chiffchaff-fg/cutted_day1_PC1101_0004.wav']\n",
      "['/teamspace/studios/this_studio/Output_files/Extended_audios/littleowl-fg/littleowl2017fg_test_108_0000.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/littleowl-fg/littleowl2017fg_test_108_0001.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/littleowl-fg/littleowl2017fg_test_108_0002.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/littleowl-fg/littleowl2017fg_test_108_0003.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/littleowl-fg/littleowl2017fg_test_108_0004.wav']\n",
      "['/teamspace/studios/this_studio/Output_files/Extended_audios/pipit-fg/pipit2017fg_more_0212_0000.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/pipit-fg/pipit2017fg_more_0212_0001.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/pipit-fg/pipit2017fg_more_0212_0002.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/pipit-fg/pipit2017fg_more_0212_0003.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/pipit-fg/pipit2017fg_more_0212_0004.wav']\n",
      "['/teamspace/studios/this_studio/Output_files/Extended_audios/rtbc-begging/32PC1_2021-22_0.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/rtbc-begging/32PC1_2021-22_1.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/rtbc-begging/32PC1_2021-22_10.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/rtbc-begging/32PC1_2021-22_11.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/rtbc-begging/32PC1_2021-22_12.wav']\n",
      "['/teamspace/studios/this_studio/Output_files/Extended_audios/littlepenguin-display_call-exhale/13B3-1_clipped/13B3-1_exhale-i10_10.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/littlepenguin-display_call-exhale/13B3-1_clipped/13B3-1_exhale-i10_77.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/littlepenguin-display_call-exhale/13B3-1_clipped/13B3-1_exhale-i11_11.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/littlepenguin-display_call-exhale/13B3-1_clipped/13B3-1_exhale-i11_78.wav', '/teamspace/studios/this_studio/Output_files/Extended_audios/littlepenguin-display_call-exhale/13B3-1_clipped/13B3-1_exhale-i12_12.wav']\n",
      "['/teamspace/studios/this_studio/Output_files/Extended_audios/greatTit_song-files/test/pf71344/20221O78_20220420_040000_100851200.WAV', '/teamspace/studios/this_studio/Output_files/Extended_audios/greatTit_song-files/test/pf71344/20221O78_20220420_040000_109139968.WAV', '/teamspace/studios/this_studio/Output_files/Extended_audios/greatTit_song-files/test/pf71344/20221O78_20220420_040000_110464256.WAV', '/teamspace/studios/this_studio/Output_files/Extended_audios/greatTit_song-files/test/pf71344/20221O78_20220420_040000_115165440.WAV', '/teamspace/studios/this_studio/Output_files/Extended_audios/greatTit_song-files/test/pf71344/20221O78_20220420_040000_115416320.WAV']\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import glob\n",
    "from birdnetlib import Recording\n",
    "from birdnetlib.analyzer import Analyzer\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = Path.cwd()\n",
    "project_root = cwd.parents[1]\n",
    "\n",
    "\n",
    "# Define una función para obtener los archivos .wav dinámicamente\n",
    "def get_audio_files(base_path, folder_name, pattern=\"**/*.[Ww][Aa][Vv]\"):\n",
    "    return glob.glob(f\"{str(base_path)}/{folder_name}/{pattern}\", recursive=True)\n",
    "\n",
    "# Define el path base\n",
    "base_path = project_root / 'Output_files' / 'Extended_audios'\n",
    "\n",
    "# Usa la función para cada dataset\n",
    "audios_chiffchaff = get_audio_files(base_path, \"chiffchaff-fg\")\n",
    "audios_littleowl = get_audio_files(base_path, \"littleowl-fg\")\n",
    "audios_pipit = get_audio_files(base_path, \"pipit-fg\")\n",
    "audios_rtbc = get_audio_files(base_path, \"rtbc-begging\")\n",
    "audios_littlepenguin = get_audio_files(base_path, \"littlepenguin-display_call-exhale\")\n",
    "audios_greatTit = get_audio_files(base_path, \"greatTit_song-files\")\n",
    "\n",
    "print(\"Files found:\")\n",
    "print(f\"Audios chiffchaff: {len(audios_chiffchaff)}\")\n",
    "print(f\"Audios littleowl: {len(audios_littleowl)}\")\n",
    "print(f\"Audios pipit: {len(audios_pipit)}\")\n",
    "print(f\"Audios rtbc: {len(audios_rtbc)}\")\n",
    "print(f\"Audios littlepenguin: {len(audios_littlepenguin)}\")\n",
    "print(f\"Audios greatTit: {len(audios_greatTit)}\")\n",
    "\n",
    "# Print the first few file paths for verification\n",
    "print(audios_chiffchaff[:5])  # Verify the first few paths generated for chiffchaff\n",
    "print(audios_littleowl[:5])  # Verify the first few paths generated for littleowl\n",
    "print(audios_pipit[:5])  # Verify the first few paths generated for pipit\n",
    "print(audios_rtbc[:5])  # Verify the first few paths generated for rtbc\n",
    "print(audios_littlepenguin[:5])  # Verify the first few paths generated for littlepenguin\n",
    "print(audios_greatTit[:5])  # Verify the first few paths generated for greatTit\n",
    "\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "output_dir = project_root / 'Output_files' / 'Embeddings_from_3sPadding'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the CSV files for each dataset\n",
    "\n",
    "csv_chiffchaff = output_dir / 'chiffchaff_embeddings.csv'\n",
    "csv_littleowl = output_dir / 'littleowl_embeddings.csv'\n",
    "csv_pipit = output_dir / 'pipit_embeddings.csv'\n",
    "csv_rtbc = output_dir / 'rtbc_embeddings.csv'\n",
    "csv_littlepenguin = output_dir / 'littlepenguin_embeddings.csv'\n",
    "csv_greatTit = output_dir / 'greatTit_embeddings.csv'\n",
    "\n",
    "\n",
    "# Decide the audio files and CSV filename to work with.\n",
    "audios = audios_littlepenguin\n",
    "csv_filename = csv_littlepenguin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels loaded.\n",
      "load model True\n",
      "Model loaded.\n",
      "Labels loaded.\n",
      "load_species_list_model\n",
      "Meta model loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to /teamspace/studios/this_studio/Output_files/Embeddings_from_3sPadding/littlepenguin_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "# Initialize the BirdNET model\n",
    "analyzer = Analyzer()\n",
    "\n",
    "# Check if the CSV file already exists to retrieve processed audio files\n",
    "if os.path.exists(csv_filename):\n",
    "    df_existing = pd.read_csv(csv_filename)\n",
    "    processed_files = set(df_existing[\"file_name\"])  # Already processed files\n",
    "else:\n",
    "    #df_existing = pd.DataFrame()\n",
    "    processed_files = set()\n",
    "\n",
    "# List of audio file paths\n",
    "\n",
    "all_data = []\n",
    "processed_count = 0  # Counter for files processed in this execution\n",
    "batch_size = 200     # Save after every 200 audios\n",
    "\n",
    "# Iterate through each file in the list of audio files\n",
    "for audio_path in audios:\n",
    "    try:\n",
    "        # Extract the file name without the path\n",
    "        file_name = os.path.basename(audio_path)\n",
    "\n",
    "        # Skip if the file has already been processed\n",
    "        if file_name in processed_files:\n",
    "            # print(f\"Skipping {file_name}, already processed.\")\n",
    "            continue\n",
    "\n",
    "        # Load the recording into BirdNET\n",
    "        recording = Recording(analyzer, audio_path)\n",
    "        recording.extract_embeddings()\n",
    "\n",
    "        # Process the extracted embeddings\n",
    "        for emb in recording.embeddings:\n",
    "            row = {\n",
    "                \"path\": audio_path,  # Full path of the file\n",
    "                \"file_name\": file_name,  # File name without the path\n",
    "                \"start_time\": emb['start_time'],\n",
    "                \"end_time\": emb['end_time']\n",
    "            }\n",
    "            # Add the 1024 embedding values\n",
    "            for i, value in enumerate(emb[\"embeddings\"]):\n",
    "                row[f\"dim_{i+1}\"] = value\n",
    "\n",
    "            all_data.append(row)\n",
    "\n",
    "        # Increment counter\n",
    "        processed_count += 1\n",
    "\n",
    "        # Save every batch_size audios\n",
    "        if processed_count % batch_size == 0:\n",
    "            df_partial = pd.DataFrame(all_data)\n",
    "            df_partial.to_csv(csv_filename, mode='a', header=not os.path.exists(csv_filename), index=False)\n",
    "            all_data = []  # Clear memory\n",
    "            print(f\"{processed_count} audios processed and saved.\")\n",
    "\n",
    "        # Clear memory\n",
    "        del recording\n",
    "        gc.collect()        \n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "\n",
    "# Save remaining data at the end\n",
    "if all_data:\n",
    "    df_partial = pd.DataFrame(all_data)\n",
    "    df_partial.to_csv(csv_filename, mode='a', header=not os.path.exists(csv_filename), index=False)\n",
    "    print(f\"Saved remaining {len(all_data)} entries.\")\n",
    "\n",
    "print(f\"Embeddings saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2429 different audios were successfully processed.\n",
      "Total audios in the original list: 2429\n",
      "Total audios processed: 2429\n",
      "Total audios not processed: 0\n",
      "Unprocessed audios:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if the CSV file already exists to retrieve processed audio files\n",
    "if os.path.exists(csv_filename):\n",
    "    df_embeddings = pd.read_csv(csv_filename)\n",
    "    processed_files = set(df_embeddings[\"file_name\"])  # Already processed files\n",
    "else:\n",
    "    df_embeddings = pd.DataFrame()\n",
    "    processed_files = set()\n",
    "\n",
    "num_processed_audios = df_embeddings[\"path\"].nunique()  # Or the correct column name\n",
    "print(f\"{num_processed_audios} different audios were successfully processed.\")\n",
    "\n",
    "# Convert the original list of audios to a set\n",
    "original_audios = set(audios)\n",
    "\n",
    "# Get the list of processed audios from the DataFrame\n",
    "processed_audios = set(df_embeddings[\"path\"].unique())\n",
    "\n",
    "# Identify the audios that were not processed\n",
    "unprocessed_audios = original_audios - processed_audios\n",
    "\n",
    "# Display results\n",
    "print(f\"Total audios in the original list: {len(original_audios)}\")\n",
    "print(f\"Total audios processed: {len(processed_audios)}\")\n",
    "print(f\"Total audios not processed: {len(unprocessed_audios)}\")\n",
    "\n",
    "# If you want to see which audios were not processed:\n",
    "print(\"Unprocessed audios:\")\n",
    "print(\"\\n\".join(unprocessed_audios))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
